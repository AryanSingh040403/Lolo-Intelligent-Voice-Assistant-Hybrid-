# ğŸ§  Lolo v2.0 â€” Hybrid Low-Latency LLM Agent

A **production-grade hybrid LLM agent** designed for **real-time voice interaction**, combining **local cognition (RAG, tools)** with a **highâ€‘performance LLM inference server**. The system is architected with **latency as a firstâ€‘class constraint**, achieving nearâ€‘human conversational fluency through concurrency, optimized model serving, and intelligent agent routing.

---

## ğŸš€ Project Overview

**Lolo v2.0** upgrades a traditional desktop voice assistant into a **cognitive hybrid AI agent** capable of:

* Realâ€‘time speech understanding and response
* Intelligent decisionâ€‘making via agentic routing
* Grounded answers using local Retrievalâ€‘Augmented Generation (RAG)
* Desktop and utility control through function calling

ğŸ”‘ **Primary Objective:**

> **Lowâ€‘latency conversational fluency with Timeâ€‘toâ€‘Firstâ€‘Audio (TTFA) â‰¤ 500 ms**

This objective directly drives the systemâ€™s **concurrent, multiâ€‘threaded pipeline** and **local-first architecture**.

---

## ğŸ§  Cognitive Architecture

The agent dynamically routes user intent through one of three execution paths:

1. **RAG Tooling** â€” For domainâ€‘specific or documentâ€‘grounded queries
2. **Function Calling** â€” For deterministic desktop or utility actions
3. **LLM Reasoning** â€” For general conversational intelligence

This **agentic rerouting** ensures correctness, speed, and grounded responses while minimizing unnecessary LLM computation.

---

## âš™ï¸ Technology Stack

### Core AI Models

* **LLM:** Qwen1.5â€‘1.8Bâ€‘Chat (4â€‘bit QLoRA)
* **Embeddings:** allâ€‘MiniLMâ€‘L6â€‘v2
* **Speechâ€‘toâ€‘Text (ASR):** fasterâ€‘whisper
* **Textâ€‘toâ€‘Speech (TTS):** Coqui XTTSâ€‘v2.2

### Frameworks & Systems

* **LLM Serving:** vLLM (OpenAIâ€‘compatible API)
* **Agent Framework:** LangChain (toolâ€‘calling agent)
* **Vector Store:** FAISS (diskâ€‘persisted, local)
* **Optimization:** bitsandbytes, PEFT, QLoRA
* **Deployment:** Docker + NVIDIA GPU

---

## ğŸ”„ Inference & Execution Pipeline

The system follows a **strict execution order** to ensure stability and performance:

1. **Environment Reset** â€” Clean virtual environment
2. **Dependency Installation** â€” Versionâ€‘pinned stable stack
3. **QLoRA Fineâ€‘Tuning** â€” Functionâ€‘calling adapter training
4. **RAG Indexing** â€” Local FAISS index construction
5. **LLM Deployment** â€” vLLM GPU server via Docker
6. **Diagnostics** â€” Agent tracing & latency monitoring
7. **Live Execution** â€” Realâ€‘time voice agent

The live agent uses a **producerâ€“consumer concurrency model**, running **ASR, LLM inference, and TTS in parallel** to mask latency.

---

## ğŸ“Š Performance & Evaluation

Latency and correctness are treated as **core KPIs**:

| Metric                    | Dimension          | Target   |
| ------------------------- | ------------------ | -------- |
| **TTFA**                  | Endâ€‘toâ€‘End Latency | â‰¤ 500 ms |
| **TTFT**                  | LLM Responsiveness | â‰¤ 350 ms |
| **Tool Call Accuracy**    | Cognitive Routing  | â‰¥ 95%    |
| **Response Groundedness** | RAG Quality        | â‰¥ 0.90   |

Latency tracing and agent decision paths are monitored via **Weights & Biases (W&B)**.

---

## ğŸ§© Data Preparation & RAG Design

* **Recursive, tokenâ€‘aware chunking**
* Chunk size: **600 tokens**
* Overlap: **100 tokens**
* Optimized for **high recall** and **low retrieval latency**

FAISS indices are persisted locally to ensure **subâ€‘second similarity search** without network dependency.

---

## ğŸ› ï¸ Prerequisites

* **Python:** â‰¤ 3.12 *(Python â‰¥ 3.13 is incompatible)*
* **Hardware:** NVIDIA GPU (required)
* **OS:** Linux / Windows (with manual audio driver setup)

> âš ï¸ All dependencies **must** be installed using the pinned versions provided. Deviations may break compatibility.

---

## âš ï¸ Limitations & Disclaimer

* **Dependency Fragility:** The stack relies on strict version pinning (bitsandbytes, vLLM, Coqui TTS)
* **Cold Start Cost:** Initial model downloads exceed 4GB; subsequent runs are cached
* **Audio I/O:** `pyaudio` and `sounddevice` may require manual systemâ€‘level configuration

---

## ğŸ“Œ Why This Project Matters

This project demonstrates:

* Systemsâ€‘level thinking for **realâ€‘time AI**
* Practical **LLM optimization and deployment**
* Agentic reasoning beyond simple prompt pipelines
* Productionâ€‘style monitoring and evaluation

It is designed as a **foundation for research, openâ€‘source extension, and realâ€‘world GenAI systems**.

---

## ğŸ¤ Contributions

Contributions, discussions, and improvements are welcome. Feel free to open an issue or submit a pull request.
